"""
Enterprise Database Layer
=========================
Suporta 5.000-10.000 lojas simultÃ¢neas com alta disponibilidade

CaracterÃ­sticas:
- âœ… Connection pooling otimizado
- âœ… Read replicas para separaÃ§Ã£o de carga
- âœ… Health checks automÃ¡ticos
- âœ… Circuit breaker pattern
- âœ… Monitoring e mÃ©tricas
- âœ… Automatic failover
- âœ… Query optimization
- âœ… Connection retry logic

Autor: PDVix Team
Ãšltima atualizaÃ§Ã£o: 2025-01-19
"""

import logging
import time
from contextlib import contextmanager
from typing import Annotated, Optional
from functools import wraps

from fastapi import Depends, HTTPException, status
from sqlalchemy import create_engine, event, text
from sqlalchemy.orm import sessionmaker, Session
from sqlalchemy.pool import QueuePool, NullPool
from sqlalchemy.exc import DBAPIError, OperationalError, DisconnectionError

from src.core.config import config

logger = logging.getLogger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURAÃ‡Ã•ES ENTERPRISE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class DatabaseConfig:
    """ConfiguraÃ§Ãµes centralizadas do banco de dados"""

    # Pool de ConexÃµes - ProduÃ§Ã£o
    PRODUCTION_POOL_SIZE = 50  # 50 conexÃµes permanentes
    PRODUCTION_MAX_OVERFLOW = 50  # AtÃ© 100 conexÃµes total
    PRODUCTION_POOL_TIMEOUT = 10  # Timeout de 10s
    PRODUCTION_POOL_RECYCLE = 1800  # Recicla a cada 30min

    # Pool de ConexÃµes - Desenvolvimento
    DEV_POOL_SIZE = 10
    DEV_MAX_OVERFLOW = 20
    DEV_POOL_TIMEOUT = 30
    DEV_POOL_RECYCLE = 3600

    # Retry Logic
    MAX_RETRIES = 3
    RETRY_DELAY = 0.5  # segundos

    # Health Check
    HEALTH_CHECK_INTERVAL = 60  # segundos

    # Circuit Breaker
    CIRCUIT_BREAKER_THRESHOLD = 5  # Falhas consecutivas para abrir
    CIRCUIT_BREAKER_TIMEOUT = 30  # Segundos em estado aberto
    CIRCUIT_BREAKER_HALF_OPEN_CALLS = 3  # Tentativas em half-open


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CIRCUIT BREAKER PATTERN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class CircuitBreaker:
    """
    ImplementaÃ§Ã£o do padrÃ£o Circuit Breaker para proteÃ§Ã£o do banco

    Estados:
    - CLOSED: Funcionando normalmente
    - OPEN: Muitas falhas, bloqueando chamadas
    - HALF_OPEN: Testando recuperaÃ§Ã£o
    """

    def __init__(self, threshold: int, timeout: int):
        self.threshold = threshold
        self.timeout = timeout
        self.failures = 0
        self.last_failure_time = None
        self.state = "CLOSED"
        self.half_open_calls = 0

    def call(self, func):
        """Decorator para proteger chamadas ao banco"""

        @wraps(func)
        def wrapper(*args, **kwargs):
            if self.state == "OPEN":
                if time.time() - self.last_failure_time > self.timeout:
                    self.state = "HALF_OPEN"
                    self.half_open_calls = 0
                    logger.info("ğŸŸ¡ Circuit Breaker: HALF_OPEN - Testando recuperaÃ§Ã£o")
                else:
                    raise HTTPException(
                        status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                        detail="Database temporarily unavailable. Please try again later."
                    )

            try:
                result = func(*args, **kwargs)
                self.on_success()
                return result
            except Exception as e:
                self.on_failure()
                raise

        return wrapper

    def on_success(self):
        """Chamada bem-sucedida"""
        if self.state == "HALF_OPEN":
            self.half_open_calls += 1
            if self.half_open_calls >= DatabaseConfig.CIRCUIT_BREAKER_HALF_OPEN_CALLS:
                self.state = "CLOSED"
                self.failures = 0
                logger.info("âœ… Circuit Breaker: CLOSED - Sistema recuperado")
        else:
            self.failures = 0

    def on_failure(self):
        """Chamada falhou"""
        self.failures += 1
        self.last_failure_time = time.time()

        if self.failures >= self.threshold:
            self.state = "OPEN"
            logger.error(
                f"ğŸ”´ Circuit Breaker: OPEN - {self.failures} falhas consecutivas. "
                f"Bloqueando chamadas por {self.timeout}s"
            )


# InstÃ¢ncia global do circuit breaker
db_circuit_breaker = CircuitBreaker(
    threshold=DatabaseConfig.CIRCUIT_BREAKER_THRESHOLD,
    timeout=DatabaseConfig.CIRCUIT_BREAKER_TIMEOUT
)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENGINE CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_engine_config() -> dict:
    """
    Retorna configuraÃ§Ã£o otimizada baseada no ambiente

    Returns:
        dict: ConfiguraÃ§Ã£o do SQLAlchemy engine
    """

    if config.is_production:
        return {
            "poolclass": QueuePool,
            "pool_size": DatabaseConfig.PRODUCTION_POOL_SIZE,
            "max_overflow": DatabaseConfig.PRODUCTION_MAX_OVERFLOW,
            "pool_timeout": DatabaseConfig.PRODUCTION_POOL_TIMEOUT,
            "pool_recycle": DatabaseConfig.PRODUCTION_POOL_RECYCLE,
            "pool_pre_ping": True,
            "pool_use_lifo": True,  # LIFO para melhor cache de conexÃµes
            "echo": False,
            "echo_pool": False,
            "connect_args": {
                "connect_timeout": 10,
                "options": "-c statement_timeout=30000",  # 30s query timeout
                "application_name": "pdvix_api",
            },
            "execution_options": {
                "isolation_level": "READ COMMITTED"
            }
        }
    elif config.is_test:
        return {
            "poolclass": NullPool,
            "echo": False,
        }
    else:
        return {
            "poolclass": QueuePool,
            "pool_size": DatabaseConfig.DEV_POOL_SIZE,
            "max_overflow": DatabaseConfig.DEV_MAX_OVERFLOW,
            "pool_timeout": DatabaseConfig.DEV_POOL_TIMEOUT,
            "pool_recycle": DatabaseConfig.DEV_POOL_RECYCLE,
            "pool_pre_ping": True,
            "echo": config.DEBUG,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENGINES (WRITE + READ REPLICAS)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Engine principal (WRITE)
engine_config = get_engine_config()
engine = create_engine(config.DATABASE_URL, **engine_config)

# Read Replica (se configurada)
read_engine = None
if hasattr(config, 'DATABASE_READ_REPLICA_URL') and config.DATABASE_READ_REPLICA_URL:
    read_engine = create_engine(config.DATABASE_READ_REPLICA_URL, **engine_config)
    logger.info("âœ… Read Replica configurada")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EVENT LISTENERS PARA MONITORAMENTO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@event.listens_for(engine, "connect")
def receive_connect(dbapi_conn, connection_record):
    """Executado quando uma nova conexÃ£o Ã© criada"""
    connection_record.info["pid"] = dbapi_conn.get_backend_pid() if hasattr(dbapi_conn, 'get_backend_pid') else None
    logger.debug("ğŸ”µ Nova conexÃ£o criada no pool")


@event.listens_for(engine, "checkout")
def receive_checkout(dbapi_conn, connection_record, connection_proxy):
    """Executado quando uma conexÃ£o Ã© retirada do pool"""
    if config.is_production:
        stats = get_pool_stats()
        if stats["utilization_percent"] > 90:
            logger.warning(
                f"âš ï¸ POOL CRÃTICO: {stats['utilization_percent']}% utilizado | "
                f"{stats['checked_out']}/{stats['max_connections']} conexÃµes"
            )


@event.listens_for(engine, "checkin")
def receive_checkin(dbapi_conn, connection_record):
    """Executado quando uma conexÃ£o retorna ao pool"""
    logger.debug("ğŸ”µ ConexÃ£o retornou ao pool")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SESSION MAKERS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SessionLocal = sessionmaker(
    autocommit=False,
    autoflush=False,
    bind=engine,
    expire_on_commit=False
)

if read_engine:
    ReadSessionLocal = sessionmaker(
        autocommit=False,
        autoflush=False,
        bind=read_engine,
        expire_on_commit=False
    )
else:
    ReadSessionLocal = SessionLocal


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RETRY LOGIC
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def retry_on_db_error(max_retries: int = DatabaseConfig.MAX_RETRIES):
    """
    Decorator para retry automÃ¡tico em erros de conexÃ£o

    âœ… VERSÃƒO CORRIGIDA: CompatÃ­vel com geradores (generators) de
    dependÃªncia do FastAPI.
    """

    def decorator(func_gen):
        @wraps(func_gen)
        def wrapper(*args, **kwargs):
            last_exception = None
            gen = None
            resource = None

            # 1. Tenta INICIAR o gerador e obter o recurso (a sessÃ£o)
            #    Isso Ã© feito dentro de um loop de retry.
            for attempt in range(max_retries):
                try:
                    # Cria o gerador (ex: chama get_db() ou get_read_db())
                    gen = func_gen(*args, **kwargs)
                    # Executa o gerador atÃ© o primeiro 'yield'
                    resource = next(gen)

                    # Se 'next(gen)' funcionou, a sessÃ£o foi criada
                    last_exception = None
                    break  # Sucesso, sai do loop de retry

                except (OperationalError, DisconnectionError, DBAPIError) as e:
                    # Falha de conexÃ£o ao tentar criar a sessÃ£o
                    last_exception = e
                    if attempt < max_retries - 1:
                        delay = DatabaseConfig.RETRY_DELAY * (2 ** attempt)  # Backoff
                        logger.warning(
                            f"âš ï¸ Erro de banco (tentativa {attempt + 1}/{max_retries}). "
                            f"Retentando em {delay}s... Erro: {str(e)}"
                        )
                        time.sleep(delay)
                    else:
                        logger.error(f"âŒ Falha ao obter sessÃ£o apÃ³s {max_retries} tentativas: {str(e)}")

                except StopIteration:
                    # O gerador nÃ£o deu 'yield' em nada
                    last_exception = RuntimeError(f"Dependency generator {func_gen.__name__} did not yield a value.")
                    break

            if last_exception:
                raise last_exception

            # 2. Se o recurso (sessÃ£o) foi obtido, dÃ¡ 'yield' para a rota
            try:
                yield resource
            except Exception as e:
                # 3. Se um erro acontece na rota, joga de volta no gerador
                #    para acionar o 'except' ou 'finally' original
                logger.error(f"âŒ Erro na sessÃ£o: {e}", exc_info=True)
                try:
                    gen.throw(e)
                except StopIteration:
                    pass
                except Exception as gen_e:
                    logger.error(f"âŒ Erro ao fechar gerador: {gen_e}", exc_info=True)
                raise  # Levanta a exceÃ§Ã£o original da rota
            else:
                # 4. Se a rota terminou sem erro, executa o 'finally' do gerador
                try:
                    next(gen)
                except StopIteration:
                    pass  # O gerador terminou normalmente

        return wrapper

    return decorator


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DATABASE DEPENDENCIES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@retry_on_db_error()
def get_db():
    """
    Dependency para operaÃ§Ãµes de ESCRITA (INSERT, UPDATE, DELETE)

    Features:
    - âœ… Retry automÃ¡tico
    - âœ… Circuit breaker
    - âœ… Rollback em erro
    - âœ… Logging de exceÃ§Ãµes
    """
    db = SessionLocal()
    try:
        yield db
    except Exception as e:
        logger.error(f"âŒ Erro na sessÃ£o de escrita: {e}", exc_info=True)
        db.rollback()
        raise
    finally:
        db.close()


@retry_on_db_error()
def get_read_db():
    """
    Dependency para operaÃ§Ãµes de LEITURA (SELECT)

    Usa read replica se disponÃ­vel, senÃ£o usa engine principal
    """
    db = ReadSessionLocal()
    try:
        yield db
    except Exception as e:
        logger.error(f"âŒ Erro na sessÃ£o de leitura: {e}", exc_info=True)
        db.rollback()
        raise
    finally:
        db.close()


get_db_manager = contextmanager(get_db)
get_read_db_manager = contextmanager(get_read_db)

GetDBDep = Annotated[Session, Depends(get_db)]
GetReadDBDep = Annotated[Session, Depends(get_read_db)]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MONITORING E HEALTH CHECKS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_pool_stats(engine_instance=None) -> dict:
    """
    Retorna estatÃ­sticas detalhadas do pool de conexÃµes

    Args:
        engine_instance: Engine especÃ­fico (padrÃ£o: engine principal)

    Returns:
        dict: EstatÃ­sticas completas do pool
    """
    if engine_instance is None:
        engine_instance = engine

    pool = engine_instance.pool

    pool_size = getattr(engine_instance.pool, '_pool', None)
    checked_out = pool.checkedout() if hasattr(pool, 'checkedout') else 0
    overflow = pool.overflow() if hasattr(pool, 'overflow') else 0
    size = pool.size() if hasattr(pool, 'size') else 0

    max_connections = engine_config.get("pool_size", 10) + engine_config.get("max_overflow", 20)

    return {
        "pool_size": size,
        "checked_in": max(0, size - checked_out),
        "checked_out": checked_out,
        "overflow": overflow,
        "total_connections": size + overflow,
        "max_connections": max_connections,
        "utilization_percent": round((checked_out / max_connections) * 100, 2) if max_connections > 0 else 0,
        "available_connections": max_connections - checked_out,
        "circuit_breaker_state": db_circuit_breaker.state,
        "circuit_breaker_failures": db_circuit_breaker.failures,
    }


def check_database_health() -> dict:
    """
    Verifica saÃºde completa do banco de dados

    Returns:
        dict: Status de saÃºde detalhado
    """
    health_status = {
        "healthy": True,
        "timestamp": time.time(),
        "checks": {}
    }

    # 1. Testa conexÃ£o com query simples
    try:
        with get_db_manager() as db:
            result = db.execute(text("SELECT 1")).scalar()
            health_status["checks"]["connection"] = {
                "status": "healthy",
                "latency_ms": 0
            }
    except Exception as e:
        health_status["healthy"] = False
        health_status["checks"]["connection"] = {
            "status": "unhealthy",
            "error": str(e)
        }

    # 2. Verifica pool stats
    pool_stats = get_pool_stats()
    health_status["checks"]["pool"] = pool_stats

    if pool_stats["utilization_percent"] > 90:
        health_status["healthy"] = False
        health_status["checks"]["pool"]["warning"] = "Pool utilization critical"

    # 3. Verifica read replica (se configurada)
    if read_engine:
        try:
            with get_read_db_manager() as db:
                result = db.execute(text("SELECT 1")).scalar()
                health_status["checks"]["read_replica"] = {
                    "status": "healthy"
                }
        except Exception as e:
            health_status["checks"]["read_replica"] = {
                "status": "unhealthy",
                "error": str(e)
            }

    # 4. Circuit breaker status
    health_status["checks"]["circuit_breaker"] = {
        "state": db_circuit_breaker.state,
        "failures": db_circuit_breaker.failures
    }

    if db_circuit_breaker.state == "OPEN":
        health_status["healthy"] = False

    return health_status


def force_close_idle_connections():
    """
    ForÃ§a fechamento de conexÃµes ociosas

    Ãštil para manutenÃ§Ã£o ou antes de fazer deploy
    """
    logger.info("ğŸ”„ ForÃ§ando fechamento de conexÃµes ociosas...")

    stats_before = get_pool_stats()
    logger.info(f"ğŸ“Š Antes: {stats_before['total_connections']} conexÃµes ativas")

    engine.dispose()

    if read_engine:
        read_engine.dispose()

    stats_after = get_pool_stats()
    logger.info(f"âœ… ApÃ³s: {stats_after['total_connections']} conexÃµes ativas")

    return {
        "before": stats_before,
        "after": stats_after
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STARTUP CHECKS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def validate_database_connection():
    """
    Valida conexÃ£o no startup da aplicaÃ§Ã£o

    Raises:
        RuntimeError: Se nÃ£o conseguir conectar ao banco
    """
    logger.info("ğŸ” Validando conexÃ£o com banco de dados...")

    try:
        with get_db_manager() as db:
            result = db.execute(text("SELECT version()")).scalar()
            logger.info(f"âœ… Conectado ao PostgreSQL: {result}")

        stats = get_pool_stats()
        logger.info(
            f"ğŸ“Š Pool de conexÃµes inicializado:\n"
            f"   â”œâ”€ Pool size: {stats['pool_size']}\n"
            f"   â”œâ”€ Max overflow: {engine_config.get('max_overflow', 0)}\n"
            f"   â””â”€ Max connections: {stats['max_connections']}"
        )

        if read_engine:
            with get_read_db_manager() as db:
                result = db.execute(text("SELECT version()")).scalar()
                logger.info(f"âœ… Read Replica conectada: {result}")

    except Exception as e:
        logger.critical(f"âŒ FALHA CRÃTICA: NÃ£o foi possÃ­vel conectar ao banco de dados: {e}")
        raise RuntimeError(f"Database connection failed: {e}")


# Executa validaÃ§Ã£o no import (apenas em produÃ§Ã£o)
if config.is_production:
    validate_database_connection()